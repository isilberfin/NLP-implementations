{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see what attributes and functions we have with nltk\n",
    "dir(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords are words that does not have a meaning seperate from the sentence \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'herself', 'been', 'with', 'here', 'very', 'doesn', 'won']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the first 500 stopwords with the interval of 25 (1. then 26. then 51...)\n",
    "stopwords.words('english')[0:500:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "messages = pd.read_csv('spam.csv', encoding ='latin-1')\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = messages.drop(labels = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
    "messages.columns = [\"label\",\"text\"]\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see the amount of data we have for each category\n",
    "messages['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nulls in labels : 0\n",
      "number of nulls in text : 0\n"
     ]
    }
   ],
   "source": [
    "#to see if we have any missing data\n",
    "print('number of nulls in labels : {}'.format(messages['label'].isnull().sum()))\n",
    "print('number of nulls in text : {}'.format(messages['text'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning text data\n",
    "there are 3 steps to clean text data:\n",
    "1. removing punctuation\n",
    "2. Tokenization\n",
    "3. removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function that will remove punctuation\n",
    "def remove_punct(text): \n",
    "    text= ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  Go until jurong point crazy Available only in ...  \n",
       "1                            Ok lar Joking wif u oni  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "3        U dun say so early hor U c already then say  \n",
       "4  Nah I dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we will apply it to our data with lambda function\n",
    "messages['text_clean'] = messages['text'].apply(lambda x : remove_punct(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                            Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        U dun say so early hor U c already then say   \n",
       "4  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                      text_tokenized  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining a function that will tokenize our cleaned text\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens =  re.split('\\W+',text)\n",
    "    return tokens\n",
    "\n",
    "messages['text_tokenized'] = messages['text_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to avoid confusion you need to add this code since stopwords is the variable that's pointing to the CorpusReader object in nltk\n",
    "#The actual stopwords (i.e. a list of stopwords) you're looking for can be adressed as :\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  Go until jurong point crazy Available only in ...   \n",
       "1                            Ok lar Joking wif u oni   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        U dun say so early hor U c already then say   \n",
       "4  Nah I dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "\n",
       "                                         text_nostop  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we will define a function to eliminate stopwords so our model will have a better understanding from prepared text\n",
    "\n",
    "def remove_stopwords(tokenized_text):\n",
    "    text = [word for word in tokenized_text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "messages['text_nostop'] = messages['text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we learned how to make this steps part by part. Now we will make it one function to move on with TF-IDF process\n",
    "def clean_text(text):\n",
    "    text= ''.join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens =  re.split('\\W+',text)\n",
    "    text = [word for word in tokens if word not in stop_words]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 9395)\n"
     ]
    }
   ],
   "source": [
    "# now we will use TF-IDF to make our text data numerical.The way that it is stored with this method is: sparse matrix\n",
    "#use analyzer as preprocessing function and then fit transform the data. The first element (number of text) is same (5572) while\n",
    "#the second part is not 2 since it represents all the unique word our TF-IDF detects\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(messages['text'])\n",
    "print(X_tfidf.shape)\n",
    "#print(tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9385</th>\n",
       "      <th>9386</th>\n",
       "      <th>9387</th>\n",
       "      <th>9388</th>\n",
       "      <th>9389</th>\n",
       "      <th>9390</th>\n",
       "      <th>9391</th>\n",
       "      <th>9392</th>\n",
       "      <th>9393</th>\n",
       "      <th>9394</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 9395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  9385  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   9386  9387  9388  9389  9390  9391  9392  9393  9394  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[3 rows x 9395 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now to train a model we need to make our sparse matrix a pandas dataframe \n",
    "\n",
    "X_features = pd.DataFrame(X_tfidf.toarray())\n",
    "X_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, messages['label'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 1.0 / Recall : 0.797\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision= precision_score(y_test, y_pred, pos_label = 'spam')\n",
    "recall = recall_score(y_test, y_pred, pos_label = 'spam')\n",
    "print('Precision : {} / Recall : {}'.format(round(precision,3),round(recall,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\isilb\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\isilb\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\isilb\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\isilb\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\isilb\\anaconda3\\lib\\site-packages (from gensim) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "#to get better results we can use pretrained embaddings from known websites, they will give better results\n",
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32307 , -0.87616 ,  0.21977 ,  0.25268 ,  0.22976 ,  0.7388  ,\n",
       "       -0.37954 , -0.35307 , -0.84369 , -1.1113  , -0.30266 ,  0.33178 ,\n",
       "       -0.25113 ,  0.30448 , -0.077491, -0.89815 ,  0.092496, -1.1407  ,\n",
       "       -0.58324 ,  0.66869 , -0.23122 , -0.95855 ,  0.28262 , -0.078848,\n",
       "        0.75315 ,  0.26584 ,  0.3422  , -0.33949 ,  0.95608 ,  0.065641,\n",
       "        0.45747 ,  0.39835 ,  0.57965 ,  0.39267 , -0.21851 ,  0.58795 ,\n",
       "       -0.55999 ,  0.63368 , -0.043983, -0.68731 , -0.37841 ,  0.38026 ,\n",
       "        0.61641 , -0.88269 , -0.12346 , -0.37928 , -0.38318 ,  0.23868 ,\n",
       "        0.6685  , -0.43321 , -0.11065 ,  0.081723,  1.1569  ,  0.78958 ,\n",
       "       -0.21223 , -2.3211  , -0.67806 ,  0.44561 ,  0.65707 ,  0.1045  ,\n",
       "        0.46217 ,  0.19912 ,  0.25802 ,  0.057194,  0.53443 , -0.43133 ,\n",
       "       -0.34311 ,  0.59789 , -0.58417 ,  0.068995,  0.23944 , -0.85181 ,\n",
       "        0.30379 , -0.34177 , -0.25746 , -0.031101, -0.16285 ,  0.45169 ,\n",
       "       -0.91627 ,  0.64521 ,  0.73281 , -0.22752 ,  0.30226 ,  0.044801,\n",
       "       -0.83741 ,  0.55006 , -0.52506 , -1.7357  ,  0.4751  , -0.70487 ,\n",
       "        0.056939, -0.7132  ,  0.089623,  0.41394 , -1.3363  , -0.61915 ,\n",
       "       -0.33089 , -0.52881 ,  0.16483 , -0.98878 ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see a vector embedding for a spesific word\n",
    "wiki_embeddings['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7682328820228577),\n",
       " ('queen', 0.7507690787315369),\n",
       " ('son', 0.7020888328552246),\n",
       " ('brother', 0.6985775232315063),\n",
       " ('monarch', 0.6977890729904175),\n",
       " ('throne', 0.6919989585876465),\n",
       " ('kingdom', 0.6811409592628479),\n",
       " ('father', 0.6802029013633728),\n",
       " ('emperor', 0.6712858080863953),\n",
       " ('ii', 0.6676074266433716)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find to words that are most similar to king based on trained vectors\n",
    "wiki_embeddings.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's see the same example with word2vec\n",
    "import pandas as pd\n",
    "messages = pd.read_csv('spam.csv', encoding ='latin-1')\n",
    "messages = messages.drop(labels = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
    "messages.columns = [\"label\",\"text\"]\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                        [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, in, wkly, comp, to, win, fa, cup...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text_clean'] = messages['text'].apply(lambda x : gensim.utils.simple_preprocess(x))\n",
    "messages.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'], messages['label'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will train the word2vec model which comes with gensim package\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06534448,  0.07740548,  0.0098363 ,  0.01370418, -0.00305823,\n",
       "       -0.11036395,  0.03916888,  0.14430027, -0.06123946, -0.01940518,\n",
       "       -0.05578702, -0.08848359, -0.01178622,  0.02408841,  0.01230709,\n",
       "       -0.02967128,  0.00807217, -0.08906545, -0.01969034, -0.15604548,\n",
       "        0.03554842,  0.08074233,  0.07598514, -0.03046089, -0.01329776,\n",
       "        0.01608412, -0.08783561, -0.05327848, -0.0487599 ,  0.05187511,\n",
       "        0.08814919,  0.01783894,  0.01663311, -0.08259889, -0.02438338,\n",
       "        0.09956935, -0.00438019, -0.09820671, -0.01771092, -0.1400168 ,\n",
       "       -0.00707782, -0.06539749, -0.02387323, -0.00306203,  0.06027883,\n",
       "       -0.00285255, -0.09187299, -0.01751372,  0.01852628,  0.04020339,\n",
       "        0.0514887 , -0.08447365, -0.01119655, -0.00038854, -0.01396212,\n",
       "        0.02000972,  0.03415037, -0.02795216, -0.07785056,  0.04497785,\n",
       "        0.01201104, -0.01521989,  0.00862918,  0.02303184, -0.05566642,\n",
       "        0.0913811 ,  0.04736568,  0.08335682, -0.11283415,  0.09193147,\n",
       "       -0.05074205,  0.0256032 ,  0.05547987, -0.02708768,  0.07103098,\n",
       "        0.02282441, -0.01336057, -0.00435988, -0.05741683,  0.01896126,\n",
       "       -0.0433132 , -0.0058215 , -0.08215368,  0.11322674, -0.04492884,\n",
       "       -0.00288944,  0.04060033,  0.0885994 ,  0.09620326,  0.02829344,\n",
       "        0.12640622,  0.01281702,  0.00797767,  0.02436981,  0.1425344 ,\n",
       "        0.0472885 ,  0.05290467, -0.05551475,  0.01820855, -0.00977708],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('after', 0.9964773654937744),\n",
       " ('msg', 0.9964723587036133),\n",
       " ('is', 0.996422529220581),\n",
       " ('said', 0.9964016675949097),\n",
       " ('with', 0.9963865280151367),\n",
       " ('im', 0.9963786005973816),\n",
       " ('last', 0.9963719844818115),\n",
       " ('games', 0.9963648915290833),\n",
       " ('of', 0.996343731880188),\n",
       " ('called', 0.9963247776031494)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can observe that when we used wikipedia embedding similar words made more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this represents aLL od the words our model created a vector for. ( all words that appears training data more than 2)\n",
    "#w2v_model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we take the every element in the x_test and turn to an array that will include learned words only\n",
    "import numpy as np\n",
    "w2v_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in w2v_model.wv.index_to_key]) for ls in X_test], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see examples of how many words are learned in a sentence.\n",
    "#for i, v in enumerate(w2v_vect):\n",
    "    #print(len(X_test.iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the vector length must be equal and equal to size of 100 as we gave in model so we will apply: \n",
    "w2v_vect_avg = []\n",
    "for vect in w2v_vect:\n",
    "    if len(vect)!= 0:\n",
    "        w2v_vect_avg.append(vect.mean(axis=0))\n",
    "    else:\n",
    "        w2v_vect_avg.append(np.zeros(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, v in enumerate(w2v_vect_avg):\n",
    "    #print(len(X_test.iloc[i]), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  doc2vec is a shallow, two layer neural network that accepts a text corpus as an input, and it returns a set of vectors \n",
    "(also known as embeddings); each vector is a numeric representation of a given sentence, paragraph or document\n",
    "instead of creating a vector for each word doc2vec creates a vector for a document(group of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for doc2vec we need to create tagged document objects to train the model\n",
    "tagged_docs = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['just', 'got', 'up', 'have', 'to', 'be', 'out', 'of', 'the', 'room', 'very', 'soon', 'û_', 'hadn', 'put', 'the', 'clocks', 'back', 'til', 'at', 'shouted', 'at', 'everyone', 'to', 'get', 'up', 'and', 'then', 'realised', 'it', 'was', 'wahay', 'another', 'hour', 'in', 'bed'], tags=[0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's look what a tagged document looks like\n",
    "tagged_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a basic doc2vec model\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs,\n",
    "                                 vector_size=100,\n",
    "                                 window=5,\n",
    "                                 min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.54809675e-03,  8.92898627e-03,  7.45030865e-03, -5.89309447e-03,\n",
       "        4.14397102e-03, -2.65573990e-02,  9.43924207e-03,  2.97321435e-02,\n",
       "       -2.11078599e-02, -1.13650328e-02, -1.58824474e-02, -2.81047560e-02,\n",
       "        2.47373641e-03,  3.97854578e-03,  4.55919374e-03, -2.14168318e-02,\n",
       "        5.85795473e-03, -1.79522689e-02, -7.29219429e-03, -4.21248078e-02,\n",
       "        1.64590981e-02,  5.59809525e-03,  1.31115252e-02, -7.84364901e-03,\n",
       "       -1.34117831e-03, -1.39555475e-03, -2.38405820e-02, -1.44826472e-02,\n",
       "       -1.53281605e-02,  6.73000654e-03,  2.39295829e-02,  3.33640887e-03,\n",
       "        1.18160993e-02, -1.84785239e-02, -6.39353553e-03,  3.57452743e-02,\n",
       "       -1.30600098e-03, -1.42853726e-02, -1.18792607e-02, -3.10618244e-02,\n",
       "       -1.16173867e-02, -1.13137616e-02, -8.32940079e-03, -3.57804284e-03,\n",
       "        2.29755584e-02, -3.59083060e-03, -2.16139574e-02, -8.07914510e-03,\n",
       "        1.21471705e-02,  1.71006303e-02,  4.90416260e-03, -1.74141396e-02,\n",
       "       -5.70918480e-03, -3.85128800e-03, -1.02283238e-02,  5.42636309e-03,\n",
       "        5.47098462e-03,  4.30550752e-03, -2.94477176e-02,  9.07627959e-03,\n",
       "       -5.00304438e-03, -1.73972454e-03, -5.14222682e-03,  5.65735390e-04,\n",
       "       -2.28608958e-02,  2.18113288e-02,  1.06715830e-02,  1.70379281e-02,\n",
       "       -3.98814715e-02,  2.24580783e-02, -5.95885515e-03,  1.21269310e-02,\n",
       "        2.09594108e-02, -5.85547369e-03,  2.64321454e-02,  7.27046560e-03,\n",
       "       -1.85253026e-04,  6.32173673e-04, -1.69353653e-02,  1.06388442e-02,\n",
       "       -1.57405809e-02, -2.72833649e-03, -2.54419502e-02,  3.21598426e-02,\n",
       "       -1.35931196e-02,  1.63658638e-03,  2.11697352e-05,  1.10150166e-02,\n",
       "        3.52671854e-02,  1.63233299e-02,  3.46109606e-02,  1.42888967e-02,\n",
       "        9.04571638e-03,  1.02193132e-02,  4.07586284e-02,  1.17177311e-02,\n",
       "        1.44982068e-02, -1.05559109e-02,  1.03303622e-02, -7.89022451e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you try to pass a single word from this model you will get an error so you need to pass a list of words\n",
    "d2v_model.infer_vector(['i','am','learning','nlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do we prepare these vectors to be used in a machine learning model?\n",
    "vectors = [[d2v_model.infer_vector(words)] for words in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01055653, -0.00972038,  0.0114952 ,  0.00807805,  0.00609327,\n",
       "        -0.01216493, -0.00361454,  0.00671203, -0.00659027, -0.00457923,\n",
       "        -0.0219323 ,  0.00110492,  0.01618778,  0.02695931,  0.00175064,\n",
       "         0.00071895,  0.00553958, -0.01323192,  0.00737582, -0.0130015 ,\n",
       "         0.00493365, -0.00190548,  0.02939511,  0.0020456 ,  0.01326407,\n",
       "         0.00415145, -0.01564152, -0.00351014,  0.00399554, -0.00722946,\n",
       "         0.02043383, -0.0001234 ,  0.00109905,  0.00391867, -0.01017171,\n",
       "        -0.00391985,  0.00840653, -0.01409786,  0.0173386 , -0.02481797,\n",
       "         0.00153598,  0.00240076, -0.00347901, -0.00440429, -0.01170508,\n",
       "        -0.00153421, -0.01564072,  0.00871679, -0.01284049,  0.00984484,\n",
       "         0.00213477,  0.00264153,  0.00161318,  0.00861747, -0.00274245,\n",
       "         0.02325118,  0.00849877, -0.00141126, -0.02058314,  0.00012791,\n",
       "         0.0082948 ,  0.00329112,  0.00896829,  0.00990194, -0.00571436,\n",
       "         0.00109737,  0.00704232,  0.00038155,  0.00035055,  0.01218178,\n",
       "         0.00585464,  0.00373354,  0.00505819, -0.00330323,  0.02515217,\n",
       "        -0.02532129, -0.01072392,  0.00729946, -0.00866714, -0.00258057,\n",
       "         0.01179996, -0.00135337, -0.00807107,  0.01850817, -0.01349455,\n",
       "         0.01356945,  0.02101671, -0.00391445, -0.00516665, -0.01237469,\n",
       "         0.01715546, -0.00097426, -0.00577285,  0.00750635,  0.00826123,\n",
       "        -0.00513845, -0.02313346, -0.01792805,  0.00768307,  0.01535565],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
